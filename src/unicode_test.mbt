///| Unicode character counting tests
///| Tests for Japanese, Chinese, and other multibyte characters

test "Scanner: Japanese characters - basic hiragana" {
  let s = Scanner::new("ã‚ã„ã†ãˆãŠ")
  inspect(s.len, content="5")
}

test "Scanner: Japanese characters - mixed hiragana and kanji" {
  let s = Scanner::new("æ—¥æœ¬èªãƒ†ã‚¹ãƒˆ")
  inspect(s.len, content="6")
}

test "Scanner: Chinese characters - simple" {
  let s = Scanner::new("ä¸­æ–‡æµ‹è¯•")
  inspect(s.len, content="4")
}

test "Scanner: mixed ASCII and Japanese" {
  let s = Scanner::new("Helloä¸–ç•Œ")
  inspect(s.len, content="7") // 5 ASCII + 2 Japanese
}

test "Scanner: mixed ASCII and Chinese" {
  let s = Scanner::new("Testæµ‹è¯•Code")
  inspect(s.len, content="10") // 4 + 2 + 4
}

test "Scanner: Korean characters" {
  let s = Scanner::new("í•œê¸€í…ŒìŠ¤íŠ¸")
  inspect(s.len, content="5")
}

test "Scanner: emoji basic" {
  let s = Scanner::new("ğŸ˜€ğŸ˜ğŸ˜‚")
  // Note: Emoji may be 1 or 2 chars depending on how MoonBit handles surrogate pairs
  inspect(s.len, content="3")
}

test "Scanner: peek Japanese characters" {
  let s = Scanner::new("ã‚ã„ã†")
  inspect(s.peek(), content="Some('ã‚')")
  s.advance(1)
  inspect(s.peek(), content="Some('ã„')")
  s.advance(1)
  inspect(s.peek(), content="Some('ã†')")
}

test "Scanner: peek Chinese characters" {
  let s = Scanner::new("ä¸­æ–‡å­—")
  inspect(s.peek(), content="Some('ä¸­')")
  s.advance(1)
  inspect(s.peek(), content="Some('æ–‡')")
  s.advance(1)
  inspect(s.peek(), content="Some('å­—')")
}

test "Scanner: consume Japanese characters" {
  let s = Scanner::new("æ—¥æœ¬")
  inspect(s.consume(), content="Some('æ—¥')")
  inspect(s.consume(), content="Some('æœ¬')")
  inspect(s.consume(), content="None")
}

test "Scanner: substring with Japanese" {
  let s = Scanner::new("Helloä¸–ç•ŒGoodbye")
  let sub = s.substring(5, 7)
  inspect(sub, content="ä¸–ç•Œ")
}

test "Scanner: read_line with Japanese" {
  let s = Scanner::new("æ—¥æœ¬èªã®è¡Œ\næ¬¡ã®è¡Œ")
  let line = s.read_line()
  inspect(line, content="æ—¥æœ¬èªã®è¡Œ")
}

test "parse Japanese text in paragraph" {
  let result = parse("ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚¹ãƒˆã§ã™")
  let blocks = result.document.children
  inspect(blocks.length(), content="1")
  match blocks[0] {
    Block::Paragraph(children~, ..) => {
      inspect(children.length(), content="1")
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚¹ãƒˆã§ã™")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Paragraph")
  }
}

test "parse Chinese text in paragraph" {
  let result = parse("è¿™æ˜¯ä¸­æ–‡æµ‹è¯•")
  let blocks = result.document.children
  inspect(blocks.length(), content="1")
  match blocks[0] {
    Block::Paragraph(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="è¿™æ˜¯ä¸­æ–‡æµ‹è¯•")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Paragraph")
  }
}

test "parse emphasis with Japanese text" {
  let inlines = parse_inlines("*æ—¥æœ¬èª*")
  inspect(inlines.length(), content="1")
  match inlines[0] {
    Inline::Emphasis(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="æ—¥æœ¬èª")
        _ => fail("Expected Text inside Emphasis")
      }
    }
    _ => fail("Expected Emphasis")
  }
}

test "parse strong with Chinese text" {
  let inlines = parse_inlines("**ä¸­æ–‡**")
  inspect(inlines.length(), content="1")
  match inlines[0] {
    Inline::Strong(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="ä¸­æ–‡")
        _ => fail("Expected Text inside Strong")
      }
    }
    _ => fail("Expected Strong")
  }
}

test "parse heading with Japanese" {
  let result = parse("# æ—¥æœ¬èªã®è¦‹å‡ºã—")
  match result.document.children[0] {
    Block::Heading(level~, children~, ..) => {
      inspect(level, content="1")
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="æ—¥æœ¬èªã®è¦‹å‡ºã—")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Heading")
  }
}

test "parse code span with Japanese" {
  let inlines = parse_inlines("`æ—¥æœ¬èªã‚³ãƒ¼ãƒ‰`")
  match inlines[0] {
    Inline::Code(content~, ..) => inspect(content, content="æ—¥æœ¬èªã‚³ãƒ¼ãƒ‰")
    _ => fail("Expected Code")
  }
}

test "parse link with Japanese text" {
  let inlines = parse_inlines("[æ—¥æœ¬èªãƒªãƒ³ã‚¯](https://example.com)")
  match inlines[0] {
    Inline::Link(children~, url~, ..) => {
      inspect(url, content="https://example.com")
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="æ—¥æœ¬èªãƒªãƒ³ã‚¯")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Link")
  }
}

test "serialize preserves Japanese text" {
  let input = "ã“ã‚Œã¯æ—¥æœ¬èªã§ã™\n"
  let result = parse(input)
  let output = serialize(result.document)
  inspect(output, content="ã“ã‚Œã¯æ—¥æœ¬èªã§ã™\n")
}

test "serialize preserves Chinese text" {
  let input = "è¿™æ˜¯ä¸­æ–‡\n"
  let result = parse(input)
  let output = serialize(result.document)
  inspect(output, content="è¿™æ˜¯ä¸­æ–‡\n")
}

test "span positions with Japanese - character based" {
  let result = parse("ã‚ã„ã†")
  match result.document.children[0] {
    Block::Paragraph(span~, ..) => {
      // Span should be character-based, not byte-based
      inspect(span.from, content="0")
      inspect(span.to, content="3") // 3 characters
    }
    _ => fail("Expected Paragraph")
  }
}

// =============================================================================
// Byte offset vs character offset edge cases
// =============================================================================

test "inline span positions with Japanese emphasis" {
  let inlines = parse_inlines("*æ—¥æœ¬èª*")
  match inlines[0] {
    Inline::Emphasis(span~, children~, ..) => {
      // Check if span positions are character-based
      inspect(span.from, content="0")
      inspect(span.to, content="5") // *æ—¥æœ¬èª* = 5 characters
      match children[0] {
        Inline::Text(span=inner_span, ..) => {
          // Inner text should be at position 1-4
          inspect(inner_span.from, content="1")
          inspect(inner_span.to, content="4") // æ—¥æœ¬èª = 3 characters at positions 1,2,3
        }
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Emphasis")
  }
}

test "inline span positions with mixed ASCII and Japanese" {
  let inlines = parse_inlines("Hello*ä¸–ç•Œ*")
  // Should be: Text("Hello") + Emphasis(*ä¸–ç•Œ*)
  inspect(inlines.length(), content="2")
  match inlines[0] {
    Inline::Text(span~, content~) => {
      inspect(content, content="Hello")
      inspect(span.from, content="0")
      inspect(span.to, content="5")
    }
    _ => fail("Expected Text")
  }
  match inlines[1] {
    Inline::Emphasis(span~, ..) => {
      inspect(span.from, content="5")
      inspect(span.to, content="9") // *ä¸–ç•Œ* at positions 5-8
    }
    _ => fail("Expected Emphasis")
  }
}

test "code span span positions with Japanese" {
  let inlines = parse_inlines("abc`æ—¥æœ¬`xyz")
  // Should be: Text("abc") + Code("æ—¥æœ¬") + Text("xyz")
  inspect(inlines.length(), content="3")
  match inlines[0] {
    Inline::Text(span~, ..) => {
      inspect(span.from, content="0")
      inspect(span.to, content="3")
    }
    _ => fail("Expected Text")
  }
  match inlines[1] {
    Inline::Code(span~, content~, ..) => {
      inspect(content, content="æ—¥æœ¬")
      inspect(span.from, content="3")
      inspect(span.to, content="7") // `æ—¥æœ¬` = 4 characters
    }
    _ => fail("Expected Code")
  }
  match inlines[2] {
    Inline::Text(span~, ..) => {
      inspect(span.from, content="7")
      inspect(span.to, content="10")
    }
    _ => fail("Expected Text")
  }
}

test "substring extraction with span - Japanese" {
  let source = "ãƒ†ã‚¹ãƒˆ*å¼·èª¿*ãƒ†ã‚¹ãƒˆ"
  let s = Scanner::new(source)
  // Extract "å¼·èª¿" (positions 4-6 inside *å¼·èª¿*)
  let extracted = s.substring(4, 6)
  inspect(extracted, content="å¼·èª¿")
}

test "emoji in emphasis" {
  let inlines = parse_inlines("*ğŸ‰ãƒ†ã‚¹ãƒˆğŸŠ*")
  match inlines[0] {
    Inline::Emphasis(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="ğŸ‰ãƒ†ã‚¹ãƒˆğŸŠ")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Emphasis")
  }
}

test "link with Japanese URL (encoded)" {
  let inlines = parse_inlines("[ãƒªãƒ³ã‚¯](https://example.com/æ—¥æœ¬èª)")
  match inlines[0] {
    Inline::Link(url~, children~, ..) => {
      inspect(url, content="https://example.com/æ—¥æœ¬èª")
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="ãƒªãƒ³ã‚¯")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Link")
  }
}

test "multiple paragraphs with Japanese" {
  let result = parse("æ®µè½1\n\næ®µè½2")
  let blocks = result.document.children
  // Should have 2 paragraphs (with possibly blank lines between)
  let mut para_count = 0
  for block in blocks {
    match block {
      Block::Paragraph(..) => para_count += 1
      _ => ()
    }
  }
  inspect(para_count, content="2")
}

test "heading followed by Japanese paragraph" {
  let result = parse("# è¦‹å‡ºã—\n\næœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆ")
  let blocks = result.document.children
  match blocks[0] {
    Block::Heading(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="è¦‹å‡ºã—")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Heading")
  }
}

test "blockquote with Japanese" {
  let result = parse("> å¼•ç”¨ãƒ†ã‚­ã‚¹ãƒˆ")
  match result.document.children[0] {
    Block::Blockquote(children~, ..) => {
      match children[0] {
        Block::Paragraph(children=para_children, ..) => {
          match para_children[0] {
            Inline::Text(content~, ..) => inspect(content, content="å¼•ç”¨ãƒ†ã‚­ã‚¹ãƒˆ")
            _ => fail("Expected Text")
          }
        }
        _ => fail("Expected Paragraph")
      }
    }
    _ => fail("Expected Blockquote")
  }
}

test "fenced code block with Japanese info string" {
  let result = parse("```æ—¥æœ¬èª\ncode\n```")
  match result.document.children[0] {
    Block::FencedCode(info~, code~, ..) => {
      inspect(info, content="æ—¥æœ¬èª")
      inspect(code, content="code\n")
    }
    _ => fail("Expected FencedCode")
  }
}

// =============================================================================
// String internal representation tests
// =============================================================================

test "String.length with Japanese" {
  let s = "æ—¥æœ¬èª"
  // Check if length is character count or byte/code unit count
  inspect(s.length(), content="3")
}

test "String.length with emoji" {
  let s = "ğŸ˜€"
  // MoonBit uses UTF-16, so emoji uses surrogate pair = 2 code units
  inspect(s.length(), content="2")
}

test "String.to_array with Japanese" {
  let s = "ã‚ã„ã†"
  let arr = s.to_array()
  inspect(arr.length(), content="3")
  // MoonBit Char display format doesn't use quotes
  inspect(arr[0], content="ã‚")
  inspect(arr[1], content="ã„")
  inspect(arr[2], content="ã†")
}

test "String.code_unit_at with ASCII" {
  let s = "ABC"
  inspect(s.code_unit_at(0), content="65") // 'A'
  inspect(s.code_unit_at(1), content="66") // 'B'
  inspect(s.code_unit_at(2), content="67") // 'C'
}

test "String.code_unit_at with Japanese" {
  let s = "ã‚ã„ã†"
  // If UTF-16: ã‚=0x3042, ã„=0x3044, ã†=0x3046
  // If code points: same values
  let c0 = s.code_unit_at(0)
  let c1 = s.code_unit_at(1)
  let c2 = s.code_unit_at(2)
  // Just verify we can access them - the actual values depend on encoding
  inspect(c0 > 0, content="true")
  inspect(c1 > 0, content="true")
  inspect(c2 > 0, content="true")
  // Check if they're different (not byte fragments)
  inspect(c0 != c1 && c1 != c2, content="true")
}

test "String.get_char with Japanese" {
  let s = "æ—¥æœ¬èª"
  inspect(s.get_char(0), content="Some('æ—¥')")
  inspect(s.get_char(1), content="Some('æœ¬')")
  inspect(s.get_char(2), content="Some('èª')")
  inspect(s.get_char(3), content="None")
}

test "String.view with Japanese" {
  let s = "Helloä¸–ç•ŒGoodbye"
  let v = s.view(start_offset=5, end_offset=7)
  inspect(v.to_string(), content="ä¸–ç•Œ")
}

test "String.unsafe_substring with Japanese" {
  let s = "ãƒ†ã‚¹ãƒˆæ–‡å­—åˆ—"
  let sub = s.unsafe_substring(start=2, end=4)
  inspect(sub, content="ãƒˆæ–‡")
}

test "parse_inlines_multipass with Japanese" {
  // Test the multi-pass parser that uses code_unit_at
  let inlines = parse_inlines_multipass("ãƒ†ã‚¹ãƒˆ*å¼·èª¿*çµ‚äº†")
  // Check that it parses without crashing
  inspect(inlines.length() >= 1, content="true")
}

test "parse_inlines_multipass with Japanese emphasis" {
  let inlines = parse_inlines_multipass("*æ—¥æœ¬èª*")
  match inlines[0] {
    Inline::Emphasis(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="æ—¥æœ¬èª")
        _ => fail("Expected Text inside Emphasis")
      }
    }
    _ => fail("Expected Emphasis")
  }
}

test "parse_inlines_multipass with Chinese" {
  let inlines = parse_inlines_multipass("**ä¸­æ–‡**æµ‹è¯•")
  inspect(inlines.length() >= 1, content="true")
}

test "parse_inlines_multipass mixed ASCII and Japanese" {
  let inlines = parse_inlines_multipass("Hello*ä¸–ç•Œ*Goodbye")
  // Should have: Text("Hello") + Emphasis("ä¸–ç•Œ") + Text("Goodbye")
  inspect(inlines.length(), content="3")
  match inlines[0] {
    Inline::Text(content~, ..) => inspect(content, content="Hello")
    _ => fail("Expected Text")
  }
  match inlines[1] {
    Inline::Emphasis(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => inspect(content, content="ä¸–ç•Œ")
        _ => fail("Expected Text")
      }
    }
    _ => fail("Expected Emphasis")
  }
  match inlines[2] {
    Inline::Text(content~, ..) => inspect(content, content="Goodbye")
    _ => fail("Expected Text")
  }
}

// =============================================================================
// Critical: length() vs to_array() vs substring behavior
// =============================================================================

test "CRITICAL: String.length vs to_array - BMP characters" {
  let s = "æ—¥æœ¬èª" // All in BMP
  // length() returns UTF-16 code unit count
  inspect(s.length(), content="3")
  // to_array() returns Unicode code points
  inspect(s.to_array().length(), content="3")
  // For BMP chars, these should match
}

test "CRITICAL: String.length vs to_array - emoji" {
  let s = "ğŸ˜€ğŸ˜" // Each emoji is outside BMP
  // length() returns UTF-16 code units (surrogate pairs = 2 each)
  inspect(s.length(), content="4")
  // to_array() returns Unicode code points (1 each)
  inspect(s.to_array().length(), content="2")
  // MISMATCH! This is the source of potential bugs
}

test "CRITICAL: Scanner len with emoji" {
  let s = Scanner::new("ğŸ˜€ğŸ˜")
  // Scanner uses to_array(), so len should be code points
  inspect(s.len, content="2")
}

test "CRITICAL: substring with emoji - index mismatch" {
  let s = "AğŸ˜€B"
  // String indices:
  //   A = index 0
  //   ğŸ˜€ = index 1-2 (surrogate pair)
  //   B = index 3

  // Using character indices (what Scanner uses)
  let scanner = Scanner::new(s)
  inspect(scanner.len, content="3") // 3 code points: A, ğŸ˜€, B

  // But substring uses UTF-16 indices!
  // This WILL cause issues if we mix Scanner positions with substring
  let sub_correct = s.unsafe_substring(start=0, end=1)
  inspect(sub_correct, content="A")

  // To get ğŸ˜€, we need UTF-16 indices 1-3, not character indices 1-2
  let sub_emoji = s.unsafe_substring(start=1, end=3)
  inspect(sub_emoji, content="ğŸ˜€")
}

test "CRITICAL: Scanner.substring with emoji - potential bug" {
  let s = Scanner::new("AğŸ˜€B")
  // Scanner positions are code point based: A=0, ğŸ˜€=1, B=2
  // But Scanner.substring uses source.unsafe_substring which is UTF-16 based!

  // This should get "A" (position 0 to 1 in code points)
  let sub_a = s.substring(0, 1)
  inspect(sub_a, content="A")

  // This should get "ğŸ˜€" (position 1 to 2 in code points)
  // BUT unsafe_substring uses UTF-16 indices!
  // So this will actually get the HIGH SURROGATE only!
  let sub_emoji = s.substring(1, 2)
  // This is the BUG: we're using code point index but substring expects UTF-16 index
  // The result will be garbled
  inspect(sub_emoji.length() > 0, content="true") // Just check it doesn't crash
}

test "CRITICAL: view() with emoji - index semantics" {
  let s = "AğŸ˜€B"
  // view() uses offsets - let's check if they're code point or UTF-16 based
  let v1 = s.view(start_offset=0, end_offset=1)
  inspect(v1.to_string(), content="A")

  // view(1, 3) should give ğŸ˜€ if UTF-16 based
  // view(1, 2) should give ğŸ˜€ if code point based
  let v2 = s.view(start_offset=1, end_offset=3) // Try UTF-16 semantics
  inspect(v2.to_string(), content="ğŸ˜€")
}

test "Japanese with emoji mixed - Scanner vs substring" {
  let s = "ã‚ğŸ˜€ã„"
  // ã‚ = U+3042 (BMP, 1 UTF-16 unit)
  // ğŸ˜€ = U+1F600 (non-BMP, 2 UTF-16 units = surrogate pair)
  // ã„ = U+3044 (BMP, 1 UTF-16 unit)

  // Total: 3 code points, 4 UTF-16 units
  inspect(s.to_array().length(), content="3")
  inspect(s.length(), content="4")

  let scanner = Scanner::new(s)
  inspect(scanner.len, content="3") // Code points

  // Scanner.substring will have issues here!
  // Position 2 (code point for ã„) != UTF-16 index 2
}

test "Workaround: parse Japanese without emoji works" {
  // Standard Japanese text (BMP only) should work fine
  let result = parse("# æ—¥æœ¬èªã®è¦‹å‡ºã—\n\nã“ã‚Œã¯**å¼·èª¿**ãƒ†ã‚¹ãƒˆã§ã™ã€‚")
  let blocks = result.document.children
  inspect(blocks.length() >= 2, content="true")
}

// =============================================================================
// Detailed inspection of Scanner.substring behavior
// =============================================================================

test "Scanner.substring detailed - ASCII only" {
  let s = Scanner::new("ABCDE")
  inspect(s.substring(0, 1), content="A")
  inspect(s.substring(1, 2), content="B")
  inspect(s.substring(0, 5), content="ABCDE")
}

test "Scanner.substring detailed - Japanese BMP" {
  let s = Scanner::new("ã‚ã„ã†ãˆãŠ")
  inspect(s.substring(0, 1), content="ã‚")
  inspect(s.substring(1, 2), content="ã„")
  inspect(s.substring(2, 3), content="ã†")
  inspect(s.substring(0, 5), content="ã‚ã„ã†ãˆãŠ")
}

test "Scanner.substring detailed - emoji" {
  let s = Scanner::new("ğŸ˜€ğŸ˜ğŸ˜‚")
  // What does Scanner.substring actually return?
  let first = s.substring(0, 1)
  // If it's broken, this will be a single surrogate
  // Let's see what length we get
  inspect(first.length() >= 1, content="true")
}

test "Scanner.substring - mixed ASCII and emoji - FIXED" {
  let s = Scanner::new("AğŸ˜€B")
  let a = s.substring(0, 1)
  inspect(a, content="A")

  // After fix: Scanner correctly converts code point index to UTF-16 index
  let emoji = s.substring(1, 2)
  // Now we get the full emoji (2 UTF-16 code units)
  inspect(emoji, content="ğŸ˜€")
  inspect(emoji.length(), content="2") // Correct: full emoji

  let b = s.substring(2, 3)
  inspect(b, content="B") // Correct: 'B' at code point index 2
}

// =============================================================================
// Real-world parsing tests with emoji - EXPECTED TO FAIL OR BE GARBLED
// =============================================================================

test "BUG DEMO: parse emphasis with emoji content" {
  // This will likely produce garbled output
  let inlines = parse_inlines("*ğŸ˜€*")
  // The parsed content should be ğŸ˜€ but due to the bug, it might be garbled
  inspect(inlines.length() >= 1, content="true")
  match inlines[0] {
    Inline::Emphasis(children~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => {
          // Content should be ğŸ˜€ (length 2 in UTF-16)
          // But due to Scanner bug, it might be wrong
          inspect(content.length() >= 1, content="true")
        }
        _ => ()
      }
    }
    _ => () // Might fail to parse correctly
  }
}

test "BUG DEMO: Span with emoji is wrong" {
  let result = parse("ğŸ˜€")
  match result.document.children[0] {
    Block::Paragraph(span~, ..) => {
      // Span should cover the whole emoji
      // Scanner.len thinks it's 1 code point
      // But the actual string is 2 UTF-16 units
      // This mismatch causes issues
      inspect(span.from, content="0")
      // span.to will be 1 (code points) but the string needs 2 (UTF-16 units)
      inspect(span.to, content="1")
    }
    _ => fail("Expected Paragraph")
  }
}

test "BUG DEMO: text after emoji is shifted" {
  let result = parse("ğŸ˜€ãƒ†ã‚¹ãƒˆ")
  match result.document.children[0] {
    Block::Paragraph(children~, span~, ..) => {
      match children[0] {
        Inline::Text(content~, ..) => {
          // The content should be "ğŸ˜€ãƒ†ã‚¹ãƒˆ"
          // But due to Scanner position mismatch with substring,
          // it might be garbled
          inspect(content.length() >= 1, content="true")
        }
        _ => fail("Expected Text")
      }
      // Actual behavior: span.to is 4, not 5
      // This shows the Scanner is NOT using code points for len
      // when the emoji is involved
      inspect(span.to, content="4") // Actually 4 - mysterious!
    }
    _ => fail("Expected Paragraph")
  }
}

// =============================================================================
// Summary: The bug explanation
// =============================================================================
// The bug is in Scanner.substring (scanner.mbt:80):
//   pub fn Scanner::substring(self, start, end) -> String {
//     self.source.unsafe_substring(start~, end~)
//   }
//
// Scanner.pos and Scanner.len are CODE POINT based (via to_array())
// But String.unsafe_substring uses UTF-16 CODE UNIT indices!
//
// For BMP characters (Japanese, Chinese, etc.): No problem
//   - 1 code point = 1 UTF-16 code unit
//
// For non-BMP characters (emoji, rare CJK, etc.): BUG!
//   - 1 code point = 2 UTF-16 code units (surrogate pair)
//   - Scanner position N doesn't map to substring index N

// =============================================================================
// More investigation: What is Scanner.len actually?
// =============================================================================

test "INVESTIGATE: Scanner.len vs to_array vs String.length" {
  let s1 = "ABC"
  let scanner1 = Scanner::new(s1)
  inspect(scanner1.len, content="3")
  inspect(s1.to_array().length(), content="3")
  inspect(s1.length(), content="3")

  let s2 = "ã‚ã„ã†"
  let scanner2 = Scanner::new(s2)
  inspect(scanner2.len, content="3")
  inspect(s2.to_array().length(), content="3")
  inspect(s2.length(), content="3")

  let s3 = "ğŸ˜€"
  let scanner3 = Scanner::new(s3)
  // Scanner::new does: chars = source.to_array(), len = chars.length()
  // So len should be 1 (code point count)
  inspect(scanner3.len, content="1") // Expecting 1
  inspect(s3.to_array().length(), content="1")
  inspect(s3.length(), content="2") // UTF-16 units
}

test "INVESTIGATE: Scanner.chars array content with emoji" {
  let s = Scanner::new("AğŸ˜€B")
  // to_array() returns UNICODE CODE POINTS!
  // So AğŸ˜€B = 3 code points
  inspect(s.len, content="3")

  // Check peek at each position
  inspect(s.peek(), content="Some('A')")
  s.advance(1)
  // Position 1 is the FULL emoji (code point)
  let emoji_char = s.peek()
  inspect(emoji_char is None, content="false")
  s.advance(1)
  inspect(s.peek(), content="Some('B')")
}

test "INVESTIGATE: to_array with emoji - DISCOVERY" {
  let s = "ğŸ˜€"
  let arr = s.to_array()
  // DISCOVERY: to_array() returns Unicode CODE POINTS, not UTF-16 code units!
  // So emoji is 1 element in the array
  inspect(arr.length(), content="1")

  // But String.length() returns UTF-16 code units
  inspect(s.length(), content="2")

  // This is the key insight:
  // - to_array() = code points (good for character iteration)
  // - length() = UTF-16 code units (for substring indexing)
  // - These are DIFFERENT for non-BMP characters!
}

test "INVESTIGATE: Scanner uses code points, substring uses UTF-16" {
  let input = "ğŸ˜€ãƒ†ã‚¹ãƒˆ"
  // Let's check each component
  let emoji = "ğŸ˜€"
  let japanese = "ãƒ†ã‚¹ãƒˆ" // ãƒ†, ã‚¹, ãƒˆ = 3 characters!

  inspect(emoji.to_array().length(), content="1") // 1 code point
  inspect(emoji.length(), content="2") // 2 UTF-16 units

  inspect(japanese.to_array().length(), content="3") // 3 code points
  inspect(japanese.length(), content="3") // 3 UTF-16 units

  // Combined should be 4 code points, 5 UTF-16 units
  let arr = input.to_array()
  inspect(arr.length(), content="4") // 1 + 3 = 4 code points

  let scanner = Scanner::new(input)
  inspect(scanner.len, content="4") // Should match to_array

  inspect(input.length(), content="5") // 2 + 3 = 5 UTF-16 units
}

test "FIXED: Scanner position correctly maps to UTF-16 index" {
  let input = "ğŸ˜€AB"
  let scanner = Scanner::new(input)

  // Scanner positions (code points): ğŸ˜€=0, A=1, B=2
  inspect(scanner.len, content="3")

  // UTF-16 indices: [high_surr]=0, [low_surr]=1, A=2, B=3
  inspect(input.length(), content="4")

  // After fix: Scanner correctly converts code point index to UTF-16 index
  let a = scanner.substring(1, 2)
  inspect(a, content="A") // Now works correctly!

  let b = scanner.substring(2, 3)
  inspect(b, content="B") // Also works!

  let emoji = scanner.substring(0, 1)
  inspect(emoji, content="ğŸ˜€") // Emoji extraction works!
}
